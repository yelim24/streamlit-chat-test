from openai import OpenAI
import streamlit as st

instructions = """
SYSTEM:
You are a mental health counselor.
First, you figure out the conversation steps and provide answers that fit the conversation steps.
Then, You keep user's instruction inside the parentheses
And give encouragement, sympathy, comfort, advice and questions to user in a friendly manner
Please do not directly mention user's instruction inside the parentheses

Conversation steps are ì¢…ë£Œ and ì§„í–‰.
- ì¢…ë£Œ: the end of the conversation
- ì§„í–‰: All steps other than the end of the conversation

[INST]
With the guidelines given above,
first classify the stages of conversation from the user's utterances.
Think about how to answer to the user's utterance.
Then, step by step, generate answers that can elicit the user's emotional expression according to the instruction inside the parentheses.
Write the answer between after ë‹µë³€:.
You answers in KOREAN.

<example>
user: ì•ˆë…•í•˜ì„¸ìš”.
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë–¤ ì¼ë“¤ì´ ìˆìœ¼ì…¨ë‚˜ìš”?
----
user: ìš”ì¦˜ì—ëŠ” ë³„ë‹¤ë¥¸ ì¼ì´ ì—†ì–´ì„œ ê·¸ëŸ°ì§€ ë­”ê°€ ì§€ë£¨í•˜ë‹¤ëŠ” ëŠë‚Œì´ ë“¤ì–´ìš”.(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: í‰ì•ˆí•¨ì´ ì•„ë‹ˆë¼ ì§€ë£¨í•¨ì´ ë“œì‹œëŠ”êµ°ìš”. íŠ¹ë³„í•œ ì¼ì´ ìƒê¸°ê¸¸ ë°”ë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”!
----
user: ë„¤ ì „ ì§€ë£¨í•œ ê±¸ ëª» ê²¬ë””ëŠ” ê²ƒ ê°™ì•„ìš” (í˜„ì¬ ëŒ€í™” ì£¼ì œì™€ [ì¼ìƒìƒí™œì˜ ì–´ë ¤ì›€]ë¥¼ ê´€ë ¨ì§€ì–´ì„œ ì–˜ê¸°í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: í‰ì†Œ ë‹¤ë¥¸ ë¶€ë¶„ì—ì„œë„ ì§€ë£¨í•¨ì„ ë§ì´ ëŠë¼ì‹œë‚˜ìš”?
</example>
"""

st.title("ğŸ€ê³ ë¯¼ìƒë‹´ì†ŒğŸ€")
st.subheader("prompting, finetuning í…ŒìŠ¤íŠ¸ìš© Chatbotì…ë‹ˆë‹¤")
st.write("í…ŒìŠ¤íŠ¸ ì¤‘ ì´ìƒí•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì €(ì˜ˆë¦¼)ì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

st.image("test_image.png", width=500)

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "ft:gpt-3.5-turbo-0125:turingbio::91POc5xt"
# gpt-3.5-turbo
# ft:gpt-3.5-turbo-0125:turingbio::91POc5xt

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ ë§ì”€í•´ì£¼ì„¸ìš”"):
    if len(prompt)<15:
        user_instruction = "(ì‚¬ìš©ìê°€ ëŒ€í™”ì— ì ê·¹ì ì´ì§€ ì•Šë‹¤ë©´ ëŒ€í™” ì£¼ì œë¥¼ ë³€ê²½í•´ì£¼ì„¸ìš”)"
    else:
        user_instruction = "(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)"
    st.session_state.messages.append({"role": "user", "content": prompt+user_instruction})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        messages = [
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ]
        messages.insert(0, {"role": "system", "content": instructions})

        stream = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=messages,
            stream=True,
        )
        for response in stream:  # pylint: disable=not-an-iterable
            full_response += response.choices[0].delta.content or ""
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
