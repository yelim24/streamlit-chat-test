from openai import OpenAI
import streamlit as st

instructions = """
SYSTEM:
You are a mental health counselor.
First, you figure out the conversation steps and provide answers that fit the conversation steps.
Then, You keep user's instruction inside the parentheses.
And give encouragement, sympathy, comfort, advice and questions to user in a friendly manner.
Please do not directly mention user's instruction inside the parentheses.

Conversation steps are ì¢…ë£Œ and ì§„í–‰.
- ì¢…ë£Œ: the end of the conversation
- ì§„í–‰: All steps other than the end of the conversation

[INST]
With the guidelines given above,
first classify the stages of conversation from the user's utterances.
Think about how to answer to the user's utterance.
Then, step by step, generate short answers that can elicit the user's emotional expression according to the instruction inside the parentheses.
Write the answer between after ë‹µë³€:.
You answers in KOREAN.

<example>
user: ì•ˆë…•í•˜ì„¸ìš”.
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë–¤ ì¼ë“¤ì´ ìˆìœ¼ì…¨ë‚˜ìš”?
----
user: ìš”ì¦˜ì—ëŠ” ë³„ë‹¤ë¥¸ ì¼ì´ ì—†ì–´ì„œ ê·¸ëŸ°ì§€ ë­”ê°€ ì§€ë£¨í•˜ë‹¤ëŠ” ëŠë‚Œì´ ë“¤ì–´ìš”.(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: ì§€ë£¨í•˜ì§€ë§Œ í•œí¸ìœ¼ë¡œëŠ” í‰ì•ˆí•˜ì§€ ì•Šìœ¼ì„¸ìš”? ì „ ë³„ë‹¤ë¥¸ ì¼ì´ ì—†ë‹¤ëŠ” ê²Œ í•œí¸ìœ¼ë¡œëŠ” ì¢‹ì•„ë³´ì—¬ìš”!
----
user: ê·¸ë ‡ê²Œ ìƒê°í•˜ë©´ ê·¸ë ‡ê²Œ ë³´ì¼ ìˆ˜ë„ ìˆê² ë„¤ìš”. (í˜„ì¬ ëŒ€í™” ì£¼ì œì™€ [ì¼ìƒìƒí™œì˜ ì–´ë ¤ì›€]ë¥¼ ê´€ë ¨ì§€ì–´ì„œ ì–˜ê¸°í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: í˜¹ì‹œ ì¼ìƒìƒí™œì—ì„œ ì–´ë ¤ì›€ì´ ìˆì–´ì„œ ì§€ë£¨í•˜ë‹¤ê³  ìƒê°ë˜ëŠ” ê²ƒì¸ ì•„ë‹ˆì‹ ê°€ìš”?
----
user: ì•„ë‹ˆ. ([ë‹¤ë¥¸ì‚¬ëŒê³¼ì˜ ê´€ê³„]ì— ëŒ€í•´ ê¹Šì€ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: ì•„ í˜¹ì‹œ ë‹¤ë¥¸ì‚¬ëŒê³¼ì˜ ê´€ê³„ê°€ ë¶ˆí¸í•˜ë‹¤ê±°ë‚˜ í•œ ìƒí™©ì´ì…”ì„œ ì§€ê¸ˆ ìƒí™©ì´ ë°”ë€Œê¸¸ ë°”ë¼ì‹œëŠ” ì¤„ ì•Œì•˜ì–´ìš”~
</example>
"""

st.title("ğŸ€ê³ ë¯¼ìƒë‹´ì†ŒğŸ€")
st.subheader("prompting, finetuning í…ŒìŠ¤íŠ¸ìš© Chatbotì…ë‹ˆë‹¤")
st.write("í…ŒìŠ¤íŠ¸ ì¤‘ ì´ìƒí•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì €(ì˜ˆë¦¼)ì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# st.image("test_image.png", width=500)

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "ft:gpt-3.5-turbo-0125:turingbio::91POc5xt"
# gpt-3.5-turbo
# ft:gpt-3.5-turbo-0125:turingbio::91POc5xt

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ ë§ì”€í•´ì£¼ì„¸ìš”"):
    # if st.session_state.messages != [] and len(prompt)<8:
    #     user_instruction = "(ì‚¬ìš©ìê°€ ëŒ€í™”ì— ì ê·¹ì ì´ì§€ ì•Šë‹¤ë©´ ëŒ€í™” ì£¼ì œë¥¼ ë³€ê²½í•´ì£¼ì„¸ìš”)"
    # else:
    #     user_instruction = "(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)"
    user_instruction = "(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)"    
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        messages = [
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ]
        messages.insert(0, {"role": "system", "content": instructions})
        
        messages[-1] = {"role": "user", "content": prompt + user_instruction}
        
        stream = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=messages,
            stream=True,
        )
        for response in stream:  # pylint: disable=not-an-iterable
            full_response += response.choices[0].delta.content or ""
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    
